---
title: "STAT421_Hw4_Sabrina Liu"
output: html_document
---

#17(c)
```{r}
c.table<-array(data = c(22,10,4,6), dim = c(2,2), dimnames = list(Strategy = c("No time-out", "time-out"), Field_goal =  c("success", "Failure")))
c.table


# Create the table of sample proportions
rowTotals = rowSums(c.table) #contains n1 and n2
n1 = rowTotals[1]
n2 = rowTotals[2]

pi.hat.table<-c.table/rowTotals
pi.hat.table

w1 = c.table[1,1]
w2 = c.table[2,1]

alpha<-0.05
pi.hat1<-pi.hat.table[1,1]
pi.hat2<-pi.hat.table[2,1]

# Relative risk where success = "MI"
round(pi.hat1/pi.hat2, 4)
round(1/(pi.hat1/pi.hat2), 4)

alpha<-0.05

# Wald interval
var.log.rr<-1/w1 - 1/n1 + 1/w2 - 1/n2
ci<-exp(log(pi.hat1/pi.hat2) + (qnorm(p = c(alpha/2, 1-alpha/2)) )* sqrt(var.log.rr))
round(ci, 4)
```

#17(d)
```{r}
###################################################################### OR

  n11 = c.table[1,1]
  n12 = c.table[1,2]
  n21 = c.table[2,1]
  n22 = c.table[2,2]

  OR.hat<-n11*n22/(n12*n21)
  round(OR.hat, 4)
  round(1/OR.hat, 4)

  alpha<-0.05
  var.log.or<-1/n11 + 1/n12 + 1/n21 + 1/n22
  OR.CI<-exp(log(OR.hat) + qnorm(p = c(alpha/2, 1-alpha/2)) * sqrt(var.log.or))
  round(OR.CI, 4)
  rev(round(1/OR.CI, 4))
```

#18(c)
```{r}
HIV.table<-array(data = c(135,15,434,9), dim = c(2,2), dimnames = list(Condom = c("Never", "Ever"), HIV =  c("Positive", "Negative")))
HIV.table

rowTotals = rowSums(HIV.table) #contains n1 and n2
n1 = rowTotals[1]
n2 = rowTotals[2]

pi.hat.table<-HIV.table/rowTotals
pi.hat.table

alpha<-0.05
pi.hat1<-pi.hat.table[1,1]
pi.hat2<-pi.hat.table[2,1]
w1 = HIV.table[1,1]
w2 = HIV.table[2,1]

##################################################################### OR

  n11 = HIV.table[1,1]
  n12 = HIV.table[1,2]
  n21 = HIV.table[2,1]
  n22 = HIV.table[2,2]

  OR.hat<-n11*n22/(n12*n21)
  round(OR.hat, 4)
  round(1/OR.hat, 4)

  alpha<-0.05
  var.log.or<-1/n11 + 1/n12 + 1/n21 + 1/n22
  OR.CI<-exp(log(OR.hat) + qnorm(p = c(alpha/2, 1-alpha/2)) * sqrt(var.log.or))
  round(OR.CI, 4)
  rev(round(1/OR.CI, 4))

```

#18(e)
```{r}
HIV.table<-array(data = c(69,81,314-69,277-81), dim = c(2,2), dimnames = list(Condome = c("Once", "More than once"), HIV =  c("Positive", "Negative")))
HIV.table

rowTotals = rowSums(HIV.table) #contains n1 and n2
n1 = rowTotals[1]
n2 = rowTotals[2]

pi.hat.table<-HIV.table/rowTotals
pi.hat.table

alpha<-0.05
pi.hat1<-pi.hat.table[1,1]
pi.hat2<-pi.hat.table[2,1]
w1 = HIV.table[1,1]
w2 = HIV.table[2,1]

##################################################################### OR

  n11 = HIV.table[1,1]
  n12 = HIV.table[1,2]
  n21 = HIV.table[2,1]
  n22 = HIV.table[2,2]

  OR.hat<-n11*n22/(n12*n21)
  round(OR.hat, 4)
  round(1/OR.hat, 4)

  alpha<-0.05
  var.log.or<-1/n11 + 1/n12 + 1/n21 + 1/n22
  OR.CI<-exp(log(OR.hat) + qnorm(p = c(alpha/2, 1-alpha/2)) * sqrt(var.log.or))
  round(OR.CI, 4)
  rev(round(1/OR.CI, 4))
```

# the OR is greater than 1, then HIV infection and the number of times married are associated (correlated) in the sense that, compared to the absence of the number of times marrie, the presence of the number of times marrie raises the odds of HIV infection, and symmetrically the presence of HIV infection raises the odds of the number of times marrie.

#19(a)
From September 2003 through December 2005, a total of 16,402 volunteers were enrolled.Thai men and women who were between the ages of 18 and 30 years and who were not infected with HIV were recruited from the community without regard to HIV risk. These considerations underscore the opportunities afforded by the efficacy testing of HIV vaccines in human subjects in providing an objective context for review of existing methods of vaccine design, immunogenicity testing, and animal models.

#19(b)
```{r}
c.table<-array(data = c(51,74,8146,8124), dim = c(2,2), dimnames = list(Treatment = c("Vaccine", "Placebo"), Response =  c("HIV", "N0-HIV")))
c.table

# Create the table of sample proportions
rowTotals = rowSums(c.table) #contains n1 and n2
n1 = rowTotals[1]
n2 = rowTotals[2]

pi.hat.table<-c.table/rowTotals
pi.hat.table

w1 = c.table[1,1]
w2 = c.table[2,1]

alpha<-0.05
pi.hat1<-pi.hat.table[1,1]
pi.hat2<-pi.hat.table[2,1]

# Relative risk where success = "MI"
round(pi.hat1/pi.hat2, 4)
round(1/(pi.hat1/pi.hat2), 4)

alpha<-0.05

# Wald interval
var.log.rr<-1/w1 - 1/n1 + 1/w2 - 1/n2
ci<-exp(log(pi.hat1/pi.hat2) + (qnorm(p = c(alpha/2, 1-alpha/2)) )* sqrt(var.log.rr))
round(ci, 4)
```

#20(a)
The population is as same as in Excersice 19. From September 2003 through December 2005, a total of 16,402 volunteers were enrolled.Thai men and women who were between the ages of 18 and 30 years and who were not infected with HIV were recruited from the community without regard to HIV risk. For table 1.10, it could be extended to the intent-to-treat data, which are these additional individuals were enrolled in the clinical trial and treated, but later were found to have been HIV positive before the trial had started. For table 1.11, it could be extended to the the per- protocol data, which is this data sample only contains those individuals,that received all four treatments of ALVAC-HIV and both treatments of AIDSVAX B/E as specified in the treatment protocol for the clinical trial. 


#20(b)
```{r}
c.table<-array(data = c(56, 76, 8146, 8124), dim = c(2,2), dimnames = list(Group = c("Vaccine", "TPlacebo"),
MI = c("HIV", "No HIV"))) #Notice how the counts are entered in by column
c.table

# Create the table of sample proportions
rowTotals = rowSums(c.table) #contains n1 and n2
n1 = rowTotals[1]
n2 = rowTotals[2]

pi.hat.table<-c.table/rowTotals
pi.hat.table #notice how R knows to divide each row by its row sum

#####################################################################
## Confidence intervals for difference of proportions

alpha<-0.05
pi.hat1<-pi.hat.table[1,1]
pi.hat2<-pi.hat.table[2,1]

# Wald
se.wald <- sqrt(pi.hat1*(1-pi.hat1)/n1 + pi.hat2*(1-pi.hat2)/n2)
round(pi.hat1 - pi.hat2 + qnorm(p = c(alpha/2, 1-alpha/2))*se.wald, 4)

# Calculate Wald interval using function in PropCIs package
library(PropCIs)
w1 = c.table[1,1]
w2 = c.table[2,1]
wald2ci(x1 = w1, n1 = n1, x2 = w2, n2 = n2, conf.level = 1-alpha, adjust = "Wald") #The 'sample estimates' attribute is actually the difference in proportions, not just the proportion from the placebo group

#Agresti-Caffo
pi.tilde1 = (w1+1)/(n1+2)
pi.tilde2 = (w2+1)/(n2+2)
pi.tilde1 - pi.tilde2
se.AC = sqrt(pi.tilde1*(1-pi.tilde1)/(n1+2) + pi.tilde2*(1-pi.tilde2)/(n2+2))
round(pi.tilde1 - pi.tilde2 + qnorm(p = c(alpha/2, 1-alpha/2))*se.AC, 4)

```

```{r}
c.table<-array(data = c(36, 50, 6140, 6316), dim = c(2,2), dimnames = list(Group = c("Vaccine", "TPlacebo"),
MI = c("HIV", "No HIV"))) #Notice how the counts are entered in by column
c.table

# Create the table of sample proportions
rowTotals = rowSums(c.table) #contains n1 and n2
n1 = rowTotals[1]
n2 = rowTotals[2]

pi.hat.table<-c.table/rowTotals
pi.hat.table #notice how R knows to divide each row by its row sum

#####################################################################
## Confidence intervals for difference of proportions

alpha<-0.05
pi.hat1<-pi.hat.table[1,1]
pi.hat2<-pi.hat.table[2,1]

# Wald
se.wald <- sqrt(pi.hat1*(1-pi.hat1)/n1 + pi.hat2*(1-pi.hat2)/n2)
round(pi.hat1 - pi.hat2 + qnorm(p = c(alpha/2, 1-alpha/2))*se.wald, 4)

# Calculate Wald interval using function in PropCIs package
library(PropCIs)
w1 = c.table[1,1]
w2 = c.table[2,1]
wald2ci(x1 = w1, n1 = n1, x2 = w2, n2 = n2, conf.level = 1-alpha, adjust = "Wald") #The 'sample estimates' attribute is actually the difference in proportions, not just the proportion from the placebo group

#Agresti-Caffo
pi.tilde1 = (w1+1)/(n1+2)
pi.tilde2 = (w2+1)/(n2+2)
pi.tilde1 - pi.tilde2
se.AC = sqrt(pi.tilde1*(1-pi.tilde1)/(n1+2) + pi.tilde2*(1-pi.tilde2)/(n2+2))
round(pi.tilde1 - pi.tilde2 + qnorm(p = c(alpha/2, 1-alpha/2))*se.AC, 4)

```

#32(a)
```{r}
# Initial settings
alpha<-0.05
pi1<-0.2
pi2<-0.4
n1<-10
n2<-10
numb.bin.samples<-1000  # Number of binomial samples


###########################################################################
# Estimated true confidence level

  # Simulate w1 and w2
  set.seed(2349)
  w1<-rbinom(n = numb.bin.samples, size = n1, prob = pi1)
  w2<-rbinom(n = numb.bin.samples, size = n2, prob = pi2)

  pi.hat1<-w1/n1
  pi.hat2<-w2/n2

  # Wald
  var.wald<-pi.hat1*(1-pi.hat1) / n1 + pi.hat2*(1-pi.hat2) / n2
  lower<-pi.hat1 - pi.hat2 - qnorm(p = 1-alpha/2) * sqrt(var.wald)
  upper<-pi.hat1 - pi.hat2 + qnorm(p = 1-alpha/2) * sqrt(var.wald)

  # Intervals 1-5
  data.frame(w1, w2, lower, upper)[1:5,]

  # Calculate estimated true confidence level
  save<-ifelse(test = pi1-pi2 > lower,
               yes = ifelse(test = pi1-pi2 < upper, yes = 1, no = 0), no = 0)
  save[1:5]
  true.conf<-mean(save)
  round(true.conf,4)

  # Agresti-Caffo
  pi.tilde1<-(w1+1)/(n1+2)
  pi.tilde2<-(w2+1)/(n2+2)
  var.AC<-pi.tilde1*(1-pi.tilde1) / (n1+2) + pi.tilde2*(1-pi.tilde2) / (n2+2)
  lower.AC<-pi.tilde1 - pi.tilde2 - qnorm(p = 1-alpha/2) * sqrt(var.AC)
  upper.AC<-pi.tilde1 - pi.tilde2 + qnorm(p = 1-alpha/2) * sqrt(var.AC)
  save.AC<-ifelse(test = pi1-pi2 > lower.AC,
                  yes = ifelse(test = pi1-pi2 < upper.AC, yes = 1, no = 0), no = 0)
  save.AC[1:10]
  true.conf.AC<-mean(save.AC)
  round(true.conf.AC,4)
```

#32(b)
```{r}
# Estimated true confidence level holding pi2 fixed at 0.3

  numb.bin.samples<-1000  # Number of binomial samples - changed to reduce simulation variability (makes plot look nicer)

  pi1seq<-seq(from = 0.001, to = 0.999, by = 0.0005)
  # pi1seq<-0.2  # Testing
  # pi1seq<-seq(from = 0.1, to = 0.9, by = 0.1)  # Testing

  # Save true confidence levels in a matrix
  save.true.conf<-matrix(data = NA, nrow = length(pi1seq), ncol = 3)

  # Create counter for the loop
  counter<-1

  set.seed(2114)
  # Loop over each pi1 that the true confidence level is calculated on
  for(pi1 in pi1seq) {
   
    w1<-rbinom(n = numb.bin.samples, size = n1, prob = pi1)
    w2<-rbinom(n = numb.bin.samples, size = n2, prob = pi2)

    pi.hat1<-w1/n1
    pi.hat2<-w2/n2

    # Wald
    lower<-pi.hat1 - pi.hat2 - qnorm(p = 1-alpha/2) *
      sqrt(pi.hat1*(1-pi.hat1) / n1 + pi.hat2*(1-pi.hat2) / n2)
    upper<-pi.hat1 - pi.hat2 + qnorm(p = 1-alpha/2) *
      sqrt(pi.hat1*(1-pi.hat1) / n1 + pi.hat2*(1-pi.hat2) / n2)
    save<-ifelse(test = pi1-pi2 > lower,
                 yes = ifelse(test = pi1-pi2 < upper, yes = 1, no = 0), no = 0)
    wald<-mean(save)

    # Agresti-Caffo
    pi.tilde1<-(w1+1)/(n1+2)
    pi.tilde2<-(w2+1)/(n2+2)
    lower.AC<-pi.tilde1 - pi.tilde2 - qnorm(p = 1-alpha/2) *
            sqrt(pi.tilde1*(1-pi.tilde1) / (n1+2) +
              pi.tilde2*(1-pi.tilde2) / (n2+2))
    upper.AC<-pi.tilde1 - pi.tilde2 + qnorm(p = 1-alpha/2) *
            sqrt(pi.tilde1*(1-pi.tilde1) / (n1+2) +
              pi.tilde2*(1-pi.tilde2) / (n2+2))
    save.AC<-ifelse(test = pi1-pi2 > lower.AC,
                    yes = ifelse(test = pi1-pi2 < upper.AC, yes = 1, no = 0), no = 0)
    AC<-mean(save.AC)
  
    save.true.conf[counter,]<-c(pi1, wald, AC)
    counter<-counter+1
  }
  
  # Plot
  x11(width = 7, height = 6, pointsize = 12)
  plot(x = save.true.conf[,1], y = save.true.conf[,2], xlab = expression(pi[1]),
    ylab = "Estimated true confidence level", type = "l", ylim = c(0.85,1), lty = "solid", col = "blue")
  lines(x = save.true.conf[,1], y = save.true.conf[,3], lty = "dashed", col = "red")
  abline(h = 1-alpha, lty = "dotted")
  legend(x = 0.1, y = 0.88, legend = c("Wald", "Agresti-Caffo"), lty = c("solid", "dashed"),
    bty = "n", col = c("blue", "red"))


```

#32(c)
```{r}
# 3D plot of the true confidence level
#   NOTE: This code can take a significant amount of time to run. We recommend
#         using the test cases of 0.1 to 0.9 by 0.1 to obtain an estimate of how
#         long it should run for the 0.001 to 0.999 by 0.0005 case. 

  # Find start time
  start.time<-proc.time()

  pi1seq<-seq(from = 0.001, to = 0.999, by = 0.0025)  # using a smaller "by" argument value can lead to slow rendering when rotating plots
  # pi1seq<-seq(from = 0.1, to = 0.9, by = 0.1)  # Testing

  pi2seq<-seq(from = 0.001, to = 0.999, by = 0.0025)
  # pi2seq<-seq(from = 0.1, to = 0.9, by = 0.1)  # Testing


  # Save true confidence levels in a matrix
  save.true.conf<-matrix(data = NA, nrow = length(pi1seq)*length(pi2seq), ncol = 4)

  # Create counter for the loop
  counter<-1

  # All possible combinations of w1 and w2
  w.all<-expand.grid(w1 = 0:n1, w2 = 0:n2)


  # All possible combinations of pi^_1 and pi^_2
  pi.hat1<-0:n1/n1
  pi.hat2<-0:n2/n2
  pi.hat.all<-expand.grid(pi.hat1 = pi.hat1, pi.hat2 = pi.hat2)
  
  # Wald
  lower<-pi.hat.all[,1] - pi.hat.all[,2] - qnorm(p = 1-alpha/2) * 
         sqrt(pi.hat.all[,1]*(1-pi.hat.all[,1]) / n1 + pi.hat.all[,2]*(1-pi.hat.all[,2]) / n2)
  upper<-pi.hat.all[,1] - pi.hat.all[,2] + qnorm(p = 1-alpha/2) * 
         sqrt(pi.hat.all[,1]*(1-pi.hat.all[,1]) / n1 + pi.hat.all[,2]*(1-pi.hat.all[,2]) / n2)

  # Agresti-Caffo
  pi1tilde<-(0:n1+1)/(n1+2)
  pi2tilde<-(0:n2+1)/(n2+2)
  pi.all.tilde<-expand.grid(pi1tilde = pi1tilde, pi2tilde = pi2tilde)
  lower.AC<-pi.all.tilde[,1] - pi.all.tilde[,2] - qnorm(p = 1-alpha/2) *
            sqrt(pi.all.tilde[,1]*(1-pi.all.tilde[,1]) / (n1+2) +
              pi.all.tilde[,2]*(1-pi.all.tilde[,2]) / (n2+2))
  upper.AC<-pi.all.tilde[,1] - pi.all.tilde[,2] + qnorm(p = 1-alpha/2) *
            sqrt(pi.all.tilde[,1]*(1-pi.all.tilde[,1]) / (n1+2) +
              pi.all.tilde[,2]*(1-pi.all.tilde[,2]) / (n2+2))


  # Loop over each pi1 and pi2 that the true confidence level is calculated on
  for(pi1 in pi1seq) {
    for(pi2 in pi2seq) {

      # Find joint probability for w1 and w2
      prob.w1<-dbinom(x = 0:n1, size = n1, prob = pi1)
      prob.w2<-dbinom(x = 0:n2, size = n2, prob = pi2)
      prob.all<-expand.grid(prob.w1 = prob.w1, prob.w2 = prob.w2)
      pmf<-prob.all$prob.w1*prob.all$prob.w2
   
      # Wald
      save<-ifelse(test = pi1-pi2 > lower,
                   yes = ifelse(test = pi1-pi2 < upper, yes = 1, no = 0), no = 0)
      wald<-sum(save*pmf)

      # Agresti-Caffo
      save.AC<-ifelse(test = pi1-pi2 > lower.AC,
                      yes = ifelse(test = pi1-pi2 < upper.AC, yes = 1, no = 0), no = 0)
      AC<-sum(save.AC*pmf)
  
      save.true.conf[counter,]<-c(pi1, pi2, wald, AC)
      counter<-counter+1
    }
  print(pi1)
  }
  
  # Find end time and total time elapsed
  end.time<-proc.time()
  save.time<-end.time-start.time
  cat("\n Number of minutes running:", save.time[3]/60, "\n \n")

  # Write file out with results to save for later (if needed)
  # write.table(x = save.true.conf, file = "c:\\chris\\save.true.conf.txt", quote = FALSE, row.names = FALSE)
  # save.true.conf<-read.table(file = "c:\\chris\\save.true.conf.txt", header = TRUE)
  
  # 3D plot package
  library(rgl) 
  
  # Wald plot with plane at 0.95
  open3d()
  persp3d(x = pi1seq, y = pi2seq, z = save.true.conf[,3], xlim = c(0,1), ylim =
      c(0,1), zlim = c(0.85, 1), xlab = "pi1", ylab = "pi2", zlab = "True confidence level", ticktype = "detailed", col="red")
  # grid3d(side = c("x-", "y-", "z"), col = "lightgray")
  true.conf<-data.frame(x = c(0,0,0.1,0.1), y = c(0,0.1,0,0.1), z = c(0.95, 
      0.95, 0.95, 0.95))
  persp3d(x = c(0,1), y = c(0,1), z = matrix(data = c(0.95,0.95, 0.95, 
      0.95), nrow = 2, ncol = 2), add = TRUE, col = "green")

  # AC plot with plane at 0.95
  open3d()
  persp3d(x = pi1seq, y = pi2seq, z = save.true.conf[,4], xlim = c(0,1), ylim =
      c(0,1), zlim = c(0.85, 1), xlab = "pi1", ylab = "pi2", zlab = "True confidence level",
      aspects = 10, ticktype = "detailed", col="red")
  # grid3d(side = c("x-", "y-", "z"), col = "lightgray")
  true.conf<-data.frame(x = c(0,0,0.1,0.1), y = c(0,0.1,0,0.1), z = c(0.95, 
      0.95, 0.95, 0.95))
  persp3d(x = c(0,1), y = c(0,1), z = matrix(data = c(0.95,0.95, 0.95, 
      0.95), nrow = 2, ncol = 2), add = TRUE, col = "green")


  # The zlim option in persp3d does not fix the axis limits like it should. Below is a fix
  #  to the problem in order to get both the Wald and AC plots on the same scale.
  test.true.conf.wald<-ifelse(test = save.true.conf[,3]<0.85, yes = NA, no = 1)
  save.true.conf.wald2<-test.true.conf.wald*save.true.conf[,3]  # Put NA's in vector if true confidence level is < 0.85
  open3d()
  persp3d(x = pi1seq, y = pi2seq, z = save.true.conf.wald2, xlim = c(0,1), ylim =
      c(0,1), xlab = "pi1", ylab = "pi2",  zlim = c(0.85, 1),
      zlab = "True confidence level", ticktype = "detailed", col="red")
  true.conf<-data.frame(x = c(0,0,0.1,0.1), y = c(0,0.1,0,0.1), z = c(0.95, 
      0.95, 0.95, 0.95))
  persp3d(x = c(0,1), y = c(0,1), z = matrix(data = c(0.95,0.95, 0.95, 
      0.95), nrow = 2, ncol = 2), add = TRUE, col = "green")
```

#32(d)
One way of stating the null hypothesis is to state that a risk ratio or an odds ratio is 1.0. We also noted that the point estimate is the most likely value, based on the observed data, and the 95% confidence interval quantifies the random error associated with our estimate, and it can also be interpreted as the range within which the true value is likely to lie with 95% confidence. This means that values outside the 95% confidence interval are unlikely to be the true value. Therefore, if the null value (RR=1.0 or OR=1.0) is not contained within the 95% confidence interval, then the probability that the null is the true value is less than 5%. Conversely, if the null is contained within the 95% confidence interval, then the null is one of the values that is consistent with the observed data, so the null hypothesis cannot be rejected. 

#32(e)
```{r}
#17
c.table<-array(data = c(22,10,4,6), dim = c(2,2), dimnames = list(Strategy = c("No time-out", "time-out"), Field_goal =  c("success", "Failure")))
c.table
alpha<-0.05
pi1<-22/26
pi2<-10/16
n1<-26
n2<-16
numb.bin.samples<-1000 

###########################################################################
# Estimated true confidence level

  # Simulate w1 and w2
  set.seed(2349)
  w1<-rbinom(n = numb.bin.samples, size = n1, prob = pi1)
  w2<-rbinom(n = numb.bin.samples, size = n2, prob = pi2)

  pi.hat1<-w1/n1
  pi.hat2<-w2/n2

  # Wald
  var.wald<-pi.hat1*(1-pi.hat1) / n1 + pi.hat2*(1-pi.hat2) / n2
  lower<-pi.hat1 - pi.hat2 - qnorm(p = 1-alpha/2) * sqrt(var.wald)
  upper<-pi.hat1 - pi.hat2 + qnorm(p = 1-alpha/2) * sqrt(var.wald)

  # Intervals 1-5
  data.frame(w1, w2, lower, upper)[1:5,]

  # Calculate estimated true confidence level
  save<-ifelse(test = pi1-pi2 > lower,
               yes = ifelse(test = pi1-pi2 < upper, yes = 1, no = 0), no = 0)
  save[1:5]
  true.conf<-mean(save)
  round(true.conf,4)

  # Agresti-Caffo
  pi.tilde1<-(w1+1)/(n1+2)
  pi.tilde2<-(w2+1)/(n2+2)
  var.AC<-pi.tilde1*(1-pi.tilde1) / (n1+2) + pi.tilde2*(1-pi.tilde2) / (n2+2)
  lower.AC<-pi.tilde1 - pi.tilde2 - qnorm(p = 1-alpha/2) * sqrt(var.AC)
  upper.AC<-pi.tilde1 - pi.tilde2 + qnorm(p = 1-alpha/2) * sqrt(var.AC)
  save.AC<-ifelse(test = pi1-pi2 > lower.AC,
                  yes = ifelse(test = pi1-pi2 < upper.AC, yes = 1, no = 0), no = 0)
  save.AC[1:10]
  true.conf.AC<-mean(save.AC)
  round(true.conf.AC,4)
  
# Estimated true confidence level holding pi2 fixed at 0.3

  numb.bin.samples<-1000  # Number of binomial samples - changed to reduce simulation variability (makes plot look nicer)

  pi1seq<-seq(from = 0.001, to = 0.999, by = 0.0005)
  # pi1seq<-0.2  # Testing
  # pi1seq<-seq(from = 0.1, to = 0.9, by = 0.1)  # Testing

  # Save true confidence levels in a matrix
  save.true.conf<-matrix(data = NA, nrow = length(pi1seq), ncol = 3)

  # Create counter for the loop
  counter<-1

  set.seed(2114)
  # Loop over each pi1 that the true confidence level is calculated on
  for(pi1 in pi1seq) {
   
    w1<-rbinom(n = numb.bin.samples, size = n1, prob = pi1)
    w2<-rbinom(n = numb.bin.samples, size = n2, prob = pi2)

    pi.hat1<-w1/n1
    pi.hat2<-w2/n2

    # Wald
    lower<-pi.hat1 - pi.hat2 - qnorm(p = 1-alpha/2) *
      sqrt(pi.hat1*(1-pi.hat1) / n1 + pi.hat2*(1-pi.hat2) / n2)
    upper<-pi.hat1 - pi.hat2 + qnorm(p = 1-alpha/2) *
      sqrt(pi.hat1*(1-pi.hat1) / n1 + pi.hat2*(1-pi.hat2) / n2)
    save<-ifelse(test = pi1-pi2 > lower,
                 yes = ifelse(test = pi1-pi2 < upper, yes = 1, no = 0), no = 0)
    wald<-mean(save)

    # Agresti-Caffo
    pi.tilde1<-(w1+1)/(n1+2)
    pi.tilde2<-(w2+1)/(n2+2)
    lower.AC<-pi.tilde1 - pi.tilde2 - qnorm(p = 1-alpha/2) *
            sqrt(pi.tilde1*(1-pi.tilde1) / (n1+2) +
              pi.tilde2*(1-pi.tilde2) / (n2+2))
    upper.AC<-pi.tilde1 - pi.tilde2 + qnorm(p = 1-alpha/2) *
            sqrt(pi.tilde1*(1-pi.tilde1) / (n1+2) +
              pi.tilde2*(1-pi.tilde2) / (n2+2))
    save.AC<-ifelse(test = pi1-pi2 > lower.AC,
                    yes = ifelse(test = pi1-pi2 < upper.AC, yes = 1, no = 0), no = 0)
    AC<-mean(save.AC)
  
    save.true.conf[counter,]<-c(pi1, wald, AC)
    counter<-counter+1
  }
  
  # Plot
  x11(width = 7, height = 6, pointsize = 12)
  plot(x = save.true.conf[,1], y = save.true.conf[,2], xlab = expression(pi[1]),
    ylab = "Estimated true confidence level", type = "l", ylim = c(0.85,1), lty = "solid", col = "blue")
  lines(x = save.true.conf[,1], y = save.true.conf[,3], lty = "dashed", col = "red")
  abline(h = 1-alpha, lty = "dotted")
  legend(x = 0.1, y = 0.88, legend = c("Wald", "Agresti-Caffo"), lty = c("solid", "dashed"),
    bty = "n", col = c("blue", "red"))

# 3D plot of the true confidence level
#   NOTE: This code can take a significant amount of time to run. We recommend
#         using the test cases of 0.1 to 0.9 by 0.1 to obtain an estimate of how
#         long it should run for the 0.001 to 0.999 by 0.0005 case. 

  # Find start time
  start.time<-proc.time()

  pi1seq<-seq(from = 0.001, to = 0.999, by = 0.0025)  # using a smaller "by" argument value can lead to slow rendering when rotating plots
  # pi1seq<-seq(from = 0.1, to = 0.9, by = 0.1)  # Testing

  pi2seq<-seq(from = 0.001, to = 0.999, by = 0.0025)
  # pi2seq<-seq(from = 0.1, to = 0.9, by = 0.1)  # Testing


  # Save true confidence levels in a matrix
  save.true.conf<-matrix(data = NA, nrow = length(pi1seq)*length(pi2seq), ncol = 4)

  # Create counter for the loop
  counter<-1

  # All possible combinations of w1 and w2
  w.all<-expand.grid(w1 = 0:n1, w2 = 0:n2)


  # All possible combinations of pi^_1 and pi^_2
  pi.hat1<-0:n1/n1
  pi.hat2<-0:n2/n2
  pi.hat.all<-expand.grid(pi.hat1 = pi.hat1, pi.hat2 = pi.hat2)
  
  # Wald
  lower<-pi.hat.all[,1] - pi.hat.all[,2] - qnorm(p = 1-alpha/2) * 
         sqrt(pi.hat.all[,1]*(1-pi.hat.all[,1]) / n1 + pi.hat.all[,2]*(1-pi.hat.all[,2]) / n2)
  upper<-pi.hat.all[,1] - pi.hat.all[,2] + qnorm(p = 1-alpha/2) * 
         sqrt(pi.hat.all[,1]*(1-pi.hat.all[,1]) / n1 + pi.hat.all[,2]*(1-pi.hat.all[,2]) / n2)

  # Agresti-Caffo
  pi1tilde<-(0:n1+1)/(n1+2)
  pi2tilde<-(0:n2+1)/(n2+2)
  pi.all.tilde<-expand.grid(pi1tilde = pi1tilde, pi2tilde = pi2tilde)
  lower.AC<-pi.all.tilde[,1] - pi.all.tilde[,2] - qnorm(p = 1-alpha/2) *
            sqrt(pi.all.tilde[,1]*(1-pi.all.tilde[,1]) / (n1+2) +
              pi.all.tilde[,2]*(1-pi.all.tilde[,2]) / (n2+2))
  upper.AC<-pi.all.tilde[,1] - pi.all.tilde[,2] + qnorm(p = 1-alpha/2) *
            sqrt(pi.all.tilde[,1]*(1-pi.all.tilde[,1]) / (n1+2) +
              pi.all.tilde[,2]*(1-pi.all.tilde[,2]) / (n2+2))


  # Loop over each pi1 and pi2 that the true confidence level is calculated on
  for(pi1 in pi1seq) {
    for(pi2 in pi2seq) {

      # Find joint probability for w1 and w2
      prob.w1<-dbinom(x = 0:n1, size = n1, prob = pi1)
      prob.w2<-dbinom(x = 0:n2, size = n2, prob = pi2)
      prob.all<-expand.grid(prob.w1 = prob.w1, prob.w2 = prob.w2)
      pmf<-prob.all$prob.w1*prob.all$prob.w2
   
      # Wald
      save<-ifelse(test = pi1-pi2 > lower,
                   yes = ifelse(test = pi1-pi2 < upper, yes = 1, no = 0), no = 0)
      wald<-sum(save*pmf)

      # Agresti-Caffo
      save.AC<-ifelse(test = pi1-pi2 > lower.AC,
                      yes = ifelse(test = pi1-pi2 < upper.AC, yes = 1, no = 0), no = 0)
      AC<-sum(save.AC*pmf)
  
      save.true.conf[counter,]<-c(pi1, pi2, wald, AC)
      counter<-counter+1
    }
  print(pi1)
  }
  
  # Find end time and total time elapsed
  end.time<-proc.time()
  save.time<-end.time-start.time
  cat("\n Number of minutes running:", save.time[3]/60, "\n \n")

  # Write file out with results to save for later (if needed)
  # write.table(x = save.true.conf, file = "c:\\chris\\save.true.conf.txt", quote = FALSE, row.names = FALSE)
  # save.true.conf<-read.table(file = "c:\\chris\\save.true.conf.txt", header = TRUE)
  
  # 3D plot package
  library(rgl) 
  
  # Wald plot with plane at 0.95
  open3d()
  persp3d(x = pi1seq, y = pi2seq, z = save.true.conf[,3], xlim = c(0,1), ylim =
      c(0,1), zlim = c(0.85, 1), xlab = "pi1", ylab = "pi2", zlab = "True confidence level", ticktype = "detailed", col="red")
  # grid3d(side = c("x-", "y-", "z"), col = "lightgray")
  true.conf<-data.frame(x = c(0,0,0.1,0.1), y = c(0,0.1,0,0.1), z = c(0.95, 
      0.95, 0.95, 0.95))
  persp3d(x = c(0,1), y = c(0,1), z = matrix(data = c(0.95,0.95, 0.95, 
      0.95), nrow = 2, ncol = 2), add = TRUE, col = "green")

  # AC plot with plane at 0.95
  open3d()
  persp3d(x = pi1seq, y = pi2seq, z = save.true.conf[,4], xlim = c(0,1), ylim =
      c(0,1), zlim = c(0.85, 1), xlab = "pi1", ylab = "pi2", zlab = "True confidence level",
      aspects = 10, ticktype = "detailed", col="red")
  # grid3d(side = c("x-", "y-", "z"), col = "lightgray")
  true.conf<-data.frame(x = c(0,0,0.1,0.1), y = c(0,0.1,0,0.1), z = c(0.95, 
      0.95, 0.95, 0.95))
  persp3d(x = c(0,1), y = c(0,1), z = matrix(data = c(0.95,0.95, 0.95, 
      0.95), nrow = 2, ncol = 2), add = TRUE, col = "green")


  # The zlim option in persp3d does not fix the axis limits like it should. Below is a fix
  #  to the problem in order to get both the Wald and AC plots on the same scale.
  test.true.conf.wald<-ifelse(test = save.true.conf[,3]<0.85, yes = NA, no = 1)
  save.true.conf.wald2<-test.true.conf.wald*save.true.conf[,3]  # Put NA's in vector if true confidence level is < 0.85
  open3d()
  persp3d(x = pi1seq, y = pi2seq, z = save.true.conf.wald2, xlim = c(0,1), ylim =
      c(0,1), xlab = "pi1", ylab = "pi2",  zlim = c(0.85, 1),
      zlab = "True confidence level", ticktype = "detailed", col="red")
  true.conf<-data.frame(x = c(0,0,0.1,0.1), y = c(0,0.1,0,0.1), z = c(0.95, 
      0.95, 0.95, 0.95))
  persp3d(x = c(0,1), y = c(0,1), z = matrix(data = c(0.95,0.95, 0.95, 
      0.95), nrow = 2, ncol = 2), add = TRUE, col = "green")
```

```{r}
#19
c.table <- array(data = c(51, 74, 8146, 8124), dim = c(2,2), dimnames = list(Trt = c("vaccine", "placebo"), Response = c("HIV", "No HIV")))
c.table
c.table[1,1]  #Row 1, column 2 count
c.table[1,]  #Row 1 count

# Find start time
  start.time<-proc.time()

  pi1seq<-seq(from = 0.001, to = 0.999, by = 0.0025)  # using a smaller "by" argument value can lead to slow rendering when rotating plots
  # pi1seq<-seq(from = 0.1, to = 0.9, by = 0.1)  # Testing

  pi2seq<-seq(from = 0.001, to = 0.999, by = 0.0025)
  # pi2seq<-seq(from = 0.1, to = 0.9, by = 0.1)  # Testing


  # Save true confidence levels in a matrix
  save.true.conf<-matrix(data = NA, nrow = length(pi1seq)*length(pi2seq), ncol = 4)

  # Create counter for the loop
  counter<-1

  # All possible combinations of w1 and w2
  w.all<-expand.grid(w1 = 0:n1, w2 = 0:n2)


  # All possible combinations of pi^_1 and pi^_2
  pi.hat1<-0:n1/n1
  pi.hat2<-0:n2/n2
  pi.hat.all<-expand.grid(pi.hat1 = pi.hat1, pi.hat2 = pi.hat2)
  
  # Wald
  lower<-pi.hat.all[,1] - pi.hat.all[,2] - qnorm(p = 1-alpha/2) * 
         sqrt(pi.hat.all[,1]*(1-pi.hat.all[,1]) / n1 + pi.hat.all[,2]*(1-pi.hat.all[,2]) / n2)
  upper<-pi.hat.all[,1] - pi.hat.all[,2] + qnorm(p = 1-alpha/2) * 
         sqrt(pi.hat.all[,1]*(1-pi.hat.all[,1]) / n1 + pi.hat.all[,2]*(1-pi.hat.all[,2]) / n2)

  # Agresti-Caffo
  pi1tilde<-(0:n1+1)/(n1+2)
  pi2tilde<-(0:n2+1)/(n2+2)
  pi.all.tilde<-expand.grid(pi1tilde = pi1tilde, pi2tilde = pi2tilde)
  lower.AC<-pi.all.tilde[,1] - pi.all.tilde[,2] - qnorm(p = 1-alpha/2) *
            sqrt(pi.all.tilde[,1]*(1-pi.all.tilde[,1]) / (n1+2) +
              pi.all.tilde[,2]*(1-pi.all.tilde[,2]) / (n2+2))
  upper.AC<-pi.all.tilde[,1] - pi.all.tilde[,2] + qnorm(p = 1-alpha/2) *
            sqrt(pi.all.tilde[,1]*(1-pi.all.tilde[,1]) / (n1+2) +
              pi.all.tilde[,2]*(1-pi.all.tilde[,2]) / (n2+2))
  # Loop over each pi1 and pi2 that the true confidence level is calculated on
  for(pi1 in pi1seq) {
    for(pi2 in pi2seq) {

      # Find joint probability for w1 and w2
      prob.w1<-dbinom(x = 0:n1, size = n1, prob = pi1)
      prob.w2<-dbinom(x = 0:n2, size = n2, prob = pi2)
      prob.all<-expand.grid(prob.w1 = prob.w1, prob.w2 = prob.w2)
      pmf<-prob.all$prob.w1*prob.all$prob.w2
   
      # Wald
      save<-ifelse(test = pi1-pi2 > lower,
                   yes = ifelse(test = pi1-pi2 < upper, yes = 1, no = 0), no = 0)
      wald<-sum(save*pmf)

      # Agresti-Caffo
      save.AC<-ifelse(test = pi1-pi2 > lower.AC,
                      yes = ifelse(test = pi1-pi2 < upper.AC, yes = 1, no = 0), no = 0)
      AC<-sum(save.AC*pmf)
  
      save.true.conf[counter,]<-c(pi1, pi2, wald, AC)
      counter<-counter+1
    }
    print(pi1)
  }
# Find end time and total time elapsed
  end.time<-proc.time()
  save.time<-end.time-start.time
  cat("\n Number of minutes running:", save.time[3]/60, "\n \n")

  # Write file out with results to save for later (if needed)
  # write.table(x = save.true.conf, file = "c:\\chris\\save.true.conf.txt", quote = FALSE, row.names = FALSE)
  # save.true.conf<-read.table(file = "c:\\chris\\save.true.conf.txt", header = TRUE)
  
  # 3D plot package
  library(rgl) 
  
  # Wald plot with plane at 0.95
  open3d()
  persp3d(x = pi1seq, y = pi2seq, z = save.true.conf[,3], xlim = c(0,1), ylim =
      c(0,1), zlim = c(0.85, 1), xlab = "pi1", ylab = "pi2", zlab = "True confidence level", ticktype = "detailed", col="red")
  # grid3d(side = c("x-", "y-", "z"), col = "lightgray")
  true.conf<-data.frame(x = c(0,0,0.1,0.1), y = c(0,0.1,0,0.1), z = c(0.95, 
      0.95, 0.95, 0.95))
  persp3d(x = c(0,1), y = c(0,1), z = matrix(data = c(0.95,0.95, 0.95, 
      0.95), nrow = 2, ncol = 2), add = TRUE, col = "green")

  # AC plot with plane at 0.95
  open3d()
  persp3d(x = pi1seq, y = pi2seq, z = save.true.conf[,4], xlim = c(0,1), ylim =
      c(0,1), zlim = c(0.85, 1), xlab = "pi1", ylab = "pi2", zlab = "True confidence level",
      aspects = 10, ticktype = "detailed", col="red")
  # grid3d(side = c("x-", "y-", "z"), col = "lightgray")
  true.conf<-data.frame(x = c(0,0,0.1,0.1), y = c(0,0.1,0,0.1), z = c(0.95, 
      0.95, 0.95, 0.95))
  persp3d(x = c(0,1), y = c(0,1), z = matrix(data = c(0.95,0.95, 0.95, 
      0.95), nrow = 2, ncol = 2), add = TRUE, col = "green")


  # The zlim option in persp3d does not fix the axis limits like it should. Below is a fix
  #  to the problem in order to get both the Wald and AC plots on the same scale.
  test.true.conf.wald<-ifelse(test = save.true.conf[,3]<0.85, yes = NA, no = 1)
  save.true.conf.wald2<-test.true.conf.wald*save.true.conf[,3]  # Put NA's in vector if true confidence level is < 0.85
  open3d()
  persp3d(x = pi1seq, y = pi2seq, z = save.true.conf.wald2, xlim = c(0,1), ylim =
      c(0,1), xlab = "pi1", ylab = "pi2",  zlim = c(0.85, 1),
      zlab = "True confidence level", ticktype = "detailed", col="red")
  true.conf<-data.frame(x = c(0,0,0.1,0.1), y = c(0,0.1,0,0.1), z = c(0.95, 
      0.95, 0.95, 0.95))
  persp3d(x = c(0,1), y = c(0,1), z = matrix(data = c(0.95,0.95, 0.95, 
      0.95), nrow = 2, ncol = 2), add = TRUE, col = "green")
```